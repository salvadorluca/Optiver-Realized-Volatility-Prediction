{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildData(bookFolder, tradeFolder):\n",
    "    if trainFolders:\n",
    "        bookFolder = bookTrainFolder\n",
    "        tradeFolder = tradeTrainFolder\n",
    "    else:\n",
    "        bookFolder = bookTestFolder\n",
    "        tradeFolder = tradeTestFolder\n",
    "\n",
    "    def buildDataForSingleStockId(stock_id_folder, stock_id_bookFolder, stock_id_tradeFolder):\n",
    "        # Read in book data for current stock_id\n",
    "        bookData = pd.read_parquet(stock_id_bookFolder + stock_id_folder)\n",
    "        tradeData = pd.read_parquet(stock_id_tradeFolder + stock_id_folder)\n",
    "        # create dataframe with all the time_id in the current bookData and all the possible seconds_in_bucket 0-599\n",
    "        time_id = []\n",
    "        seconds_in_bucket = []\n",
    "\n",
    "        for x in bookData['time_id'].unique():\n",
    "            for y in range(600):\n",
    "                time_id.append(x)\n",
    "                seconds_in_bucket.append(y)\n",
    "\n",
    "        allTimes = pd.DataFrame({'time_id': time_id, 'seconds_in_bucket': seconds_in_bucket})\n",
    "\n",
    "        # Ensure all seconds are accounted for\n",
    "        bookData = bookData.merge(allTimes, on=['time_id', 'seconds_in_bucket'], how='outer').sort_values(by=['time_id', 'seconds_in_bucket'])\n",
    "        bookData['time_id_cp'] = bookData['time_id']\n",
    "\n",
    "        # Forward fill and backfill\n",
    "        bookData = bookData.groupby(['time_id_cp']).fillna(method='ffill').fillna(method='bfill').reset_index(drop=True)\n",
    "\n",
    "        # Calculate weighted average price\n",
    "        bookData['wap1'] = (bookData['bid_price1'] * bookData['ask_size1'] + bookData['ask_price1'] * bookData['bid_size1']) / (bookData['ask_size1'] + bookData['bid_size1'])\n",
    "        bookData['wap2'] = (bookData['bid_price2'] * bookData['ask_size2'] + bookData['ask_price2'] * bookData['bid_size2']) / (bookData['ask_size2'] + bookData['bid_size2'])\n",
    "        bookData['ask1_bid1_spread'] = bookData['ask_price1'] / bookData['bid_price1'] - 1\n",
    "        # bid spread and ask spread\n",
    "        bookData['bid_spread'] = (bookData['bid_price1'] - bookData['bid_price2']) / (bookData['bid_price1'] + bookData['bid_price2'])\n",
    "        bookData['ask_spread'] = (bookData['ask_price2'] - bookData['ask_price1']) / (bookData['ask_price1'] + bookData['ask_price2'])\n",
    "\n",
    "        df1 = pd.merge(bookData, tradeData[['time_id', 'seconds_in_bucket','price']], on = ['time_id', 'seconds_in_bucket'], how = 'left')\n",
    "        df1 = df1.fillna(0)\n",
    "\n",
    "        def aggregateBookData(interval):\n",
    "            df = df1.copy()\n",
    "            df['interval'] = df['seconds_in_bucket'] // interval\n",
    "\n",
    "            df_agg = df.groupby(['time_id', 'interval']).agg(\n",
    "                wap1_log_high_low=pd.NamedAgg(column='wap1', aggfunc=lambda x: np.log(np.max(x) / np.min(x))),\n",
    "                wap2_log_high_low=pd.NamedAgg(column='wap2', aggfunc=lambda x: np.log(np.max(x) / np.min(x))),\n",
    "                ask1_bid1_spread_avg=pd.NamedAgg(column='ask1_bid1_spread', aggfunc=np.mean),\n",
    "                bid_spread_avg=pd.NamedAgg(column='bid_spread', aggfunc=np.mean),\n",
    "                ask_spread_avg=pd.NamedAgg(column='ask_spread', aggfunc=np.mean),\n",
    "                price_avg = pd.NamedAgg(column = 'price', aggfunc=np.mean)).reset_index()\n",
    "\n",
    "            df_wide = pd.pivot_table(df_agg, values=['wap1_log_high_low', 'wap2_log_high_low', 'ask1_bid1_spread_avg','price_avg', 'bid_spread_avg', 'ask_spread_avg'],\n",
    "                                     index='time_id', columns='interval').reset_index().fillna(0)\n",
    "            df_wide.columns = ['_'.join(str(e) for e in col) for col in df_wide.columns]\n",
    "            df_wide = df_wide.add_suffix(f'_{interval}s_wide').rename(columns={f'time_id__{interval}s_wide': 'time_id'})\n",
    "\n",
    "            return df_wide\n",
    "\n",
    "        finalBookData = aggregateBookData(10)\n",
    "        finalBookData['row_id'] = stock_id_folder.split('=')[1] + '-' + finalBookData['time_id'].astype(str)\n",
    "        \n",
    "\n",
    "        return finalBookData.drop(columns='time_id').fillna(0)\n",
    "\n",
    "    results = []\n",
    "    for curr_stock_id_folder in os.listdir(bookFolder):\n",
    "        if curr_stock_id_folder.startswith('stock_id='):\n",
    "            results.append(buildDataForSingleStockId(curr_stock_id_folder, bookFolder, tradeFolder))\n",
    "\n",
    "\n",
    "    return pd.concat(results, ignore_index=True).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookTrainFolder = 'book_train.parquet/'\n",
    "tradeTrainFolder = 'trade_train.parquet/'\n",
    "\n",
    "print(f\"Number of files in booktrain: {len(os.listdir(bookTrainFolder))}\")\n",
    "\n",
    "trainData1 = buildData(bookTrainFolder, tradeTrainFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the 'row_id' into 'stock_id' and 'time_id'\n",
    "trainData1['stock_id'], trainData1['time_id'] = zip(\n",
    "    *trainData1['row_id'].apply(lambda x: map(int, x.split('-')))\n",
    ")\n",
    "result = pd.merge(trainData1, train_csv, on=['stock_id', 'time_id'], how='left')\n",
    "\n",
    "result.drop(columns=['row_id'], inplace=True)\n",
    "result['stock_id'] = result['stock_id'].astype(int)\n",
    "result['time_id'] = result['time_id'].astype(int)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_replace = [col for col in trainData1.columns if col.startswith('price')]\n",
    "\n",
    "result[columns_to_replace] = result[columns_to_replace].applymap(lambda x: 1 if x > 0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Splitting the data into training and testing sets\n",
    "train_data, temp_data = train_test_split(result, test_size=0.2, random_state=42)\n",
    "\n",
    "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
    "\n",
    "train_data.to_parquet('train.parquet')\n",
    "val_data.to_parquet('val.parquet')\n",
    "test_data.to_parquet('test.parquet')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
